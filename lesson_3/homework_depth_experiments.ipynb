{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70401a22",
   "metadata": {},
   "source": [
    "# Домашнее задание к уроку 3: Полносвязные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ae408",
   "metadata": {},
   "source": [
    "Задание 1: Эксперименты с глубиной сети (30 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e7676",
   "metadata": {},
   "source": [
    "Для экспериментов буду использовать датасет Титаник из прошлого урока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809f0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationMetrics:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Инициализация класса метрик классификации\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def to_one_hot(self, labels, num_classes):\n",
    "        \"\"\"\n",
    "        Преобразование меток в one-hot encoding\n",
    "        \n",
    "        Args:\n",
    "            labels: тензор меток (batch_size,)\n",
    "            num_classes: количество классов\n",
    "            \n",
    "        Returns:\n",
    "            one-hot тензор (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        return torch.nn.functional.one_hot(labels, num_classes).float()\n",
    "\n",
    "    def precision(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики Precision\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            precision score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        \n",
    "        if average == 'micro':\n",
    "            true_positives = torch.sum(y_true == y_pred).float()\n",
    "            predicted_positives = len(y_pred)\n",
    "            return true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "        \n",
    "        precision_per_class = []\n",
    "        weights = []\n",
    "        \n",
    "        for c in range(num_classes):\n",
    "            true_positives = torch.sum((y_true == c) & (y_pred == c)).float()\n",
    "            predicted_positives = torch.sum(y_pred == c).float()\n",
    "            \n",
    "            precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "            precision_per_class.append(precision)\n",
    "            \n",
    "            if average == 'weighted':\n",
    "                weights.append(torch.sum(y_true == c).float() / len(y_true))\n",
    "        \n",
    "        precision_per_class = torch.tensor(precision_per_class)\n",
    "        \n",
    "        if average == 'macro':\n",
    "            return torch.mean(precision_per_class).item()\n",
    "        elif average == 'weighted':\n",
    "            return torch.sum(precision_per_class * torch.tensor(weights)).item()\n",
    "        \n",
    "        return precision_per_class.tolist()\n",
    "\n",
    "    def recall(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики Recall\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            recall score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        \n",
    "        if average == 'micro':\n",
    "            true_positives = torch.sum(y_true == y_pred).float()\n",
    "            actual_positives = len(y_true)\n",
    "            return true_positives / actual_positives if actual_positives > 0 else 0\n",
    "        \n",
    "        recall_per_class = []\n",
    "        weights = []\n",
    "        \n",
    "        for c in range(num_classes):\n",
    "            true_positives = torch.sum((y_true == c) & (y_pred == c)).float()\n",
    "            actual_positives = torch.sum(y_true == c).float()\n",
    "            \n",
    "            recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "            recall_per_class.append(recall)\n",
    "            \n",
    "            if average == 'weighted':\n",
    "                weights.append(torch.sum(y_true == c).float() / len(y_true))\n",
    "        \n",
    "        recall_per_class = torch.tensor(recall_per_class)\n",
    "        \n",
    "        if average == 'macro':\n",
    "            return torch.mean(recall_per_class).item()\n",
    "        elif average == 'weighted':\n",
    "            return torch.sum(recall_per_class * torch.tensor(weights)).item()\n",
    "        \n",
    "        return recall_per_class.tolist()\n",
    "\n",
    "    def f1_score(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики F1-score\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            f1 score\n",
    "        \"\"\"\n",
    "        precision = self.precision(y_true, y_pred, average)\n",
    "        recall = self.recall(y_true, y_pred, average)\n",
    "        \n",
    "        if average in ['macro', 'weighted']:\n",
    "            return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        elif average == 'micro':\n",
    "            return precision\n",
    "        \n",
    "        f1_scores = []\n",
    "        for p, r in zip(precision, recall):\n",
    "            f1 = 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "            f1_scores.append(f1)\n",
    "        return f1_scores\n",
    "\n",
    "    def roc_auc(self, y_true, y_scores, multi_class='ovr'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики ROC-AUC\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_scores: вероятности предсказаний (batch_size, num_classes)\n",
    "            multi_class: 'ovr' (one-vs-rest) или 'ovo' (one-vs-one)\n",
    "            \n",
    "        Returns:\n",
    "            roc-auc score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).cpu().numpy()\n",
    "        y_scores = torch.tensor(y_scores, dtype=torch.float).cpu().numpy()\n",
    "        \n",
    "        num_classes = y_scores.shape[1]\n",
    "        y_true_one_hot = self.to_one_hot(torch.tensor(y_true), num_classes).cpu().numpy()\n",
    "        \n",
    "        auc_scores = []\n",
    "        \n",
    "        if multi_class == 'ovr':\n",
    "            for i in range(num_classes):\n",
    "                fpr, tpr, _ = roc_curve(y_true_one_hot[:, i], y_scores[:, i])\n",
    "                auc_score = auc(fpr, tpr)\n",
    "                auc_scores.append(auc_score)\n",
    "            return np.mean(auc_scores)\n",
    "        \n",
    "        elif multi_class == 'ovo':\n",
    "            auc_sum = 0\n",
    "            n_pairs = 0\n",
    "            for i in range(num_classes):\n",
    "                for j in range(i+1, num_classes):\n",
    "                    mask = np.logical_or(y_true == i, y_true == j)\n",
    "                    y_true_binary = (y_true[mask] == i).astype(int)\n",
    "                    y_scores_binary = y_scores[mask, i] / (y_scores[mask, i] + y_scores[mask, j])\n",
    "                    fpr, tpr, _ = roc_curve(y_true_binary, y_scores_binary)\n",
    "                    auc_sum += auc(fpr, tpr)\n",
    "                    n_pairs += 1\n",
    "            return auc_sum / n_pairs if n_pairs > 0 else 0\n",
    "        \n",
    "        return auc_scores\n",
    "\n",
    "    def confusion_matrix(self, y_true, y_pred, plot=True, save_path=None):\n",
    "        \"\"\"\n",
    "        Вычисление и визуализация confusion matrix с возможностью сохранения\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            plot: флаг для отображения визуализации\n",
    "            save_path: путь для сохранения графика (например, 'confusion_matrix.png')\n",
    "            \n",
    "        Returns:\n",
    "            confusion matrix\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        cm = torch.zeros((num_classes, num_classes), dtype=torch.long)\n",
    "        \n",
    "        for t, p in zip(y_true, y_pred):\n",
    "            cm[t, p] += 1\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm.numpy(), annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            \n",
    "            if save_path:\n",
    "                # Создаём директорию, если она не существует\n",
    "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "                print(f\"Confusion matrix сохранена в {save_path}\")\n",
    "            \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "        return cm\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path_file, numeric_columns: list, string_columns: list, binary_columns: list, target_column: str):\n",
    "        self.path_file = path_file\n",
    "        self.numeric_columns = numeric_columns\n",
    "        self.string_columns = string_columns\n",
    "        self.binary_columns = binary_columns\n",
    "        self.target_column = target_column\n",
    "        self.label_encoders = {}\n",
    "        self.one_hot_encoders = {}\n",
    "\n",
    "        self.df = pd.read_csv(path_file)\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "        self._convert_numeric()\n",
    "        self._convert_string()\n",
    "        self._convert_binary()\n",
    "\n",
    "    def _convert_numeric(self):\n",
    "        if self.numeric_columns:\n",
    "            scaler = StandardScaler()\n",
    "            self.df[self.numeric_columns] = scaler.fit_transform(self.df[self.numeric_columns])\n",
    "\n",
    "    def _convert_string(self):\n",
    "        if self.string_columns:\n",
    "            for column in self.string_columns:\n",
    "                le = LabelEncoder()\n",
    "                self.df[column] = self.df[column].fillna('missing')\n",
    "                self.df[column] = le.fit_transform(self.df[column])\n",
    "                self.label_encoders[column] = le\n",
    "\n",
    "    def _convert_binary(self):\n",
    "        if self.binary_columns:\n",
    "            for column in self.binary_columns:\n",
    "                encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "                transformed = encoder.fit_transform(self.df[[column]])\n",
    "                new_columns = [f\"{column}_{cat}\" for cat in encoder.categories_[0][1:]]\n",
    "                self.df[new_columns] = transformed\n",
    "                self.df = self.df.drop(column, axis=1)\n",
    "                self.one_hot_encoders[column] = encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_one_row = self.df.iloc[index]\n",
    "        train = data_one_row.drop(self.target_column).values.astype(np.float32)  # Преобразуем в numpy float32\n",
    "        target = np.array(data_one_row[self.target_column], dtype=np.float32)  # Преобразуем в numpy float32\n",
    "        return torch.tensor(train), torch.tensor(target)  # Возвращаем тензоры\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self,in_features,out_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features,out_features)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layer1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac54cb",
   "metadata": {},
   "source": [
    "<h3>Описание названия колонок:</h3>\n",
    "<ul>\n",
    "<li>survival - Выживание (0 = Нет; 1 = Да)(target)</li>\n",
    "<li>pclass - Класс пассажира (1 = 1-й; 2 = 2-й; 3 = 3-й)</li>\n",
    "<li>sex - Пол</li>\n",
    "<li>age - Возраст</li>\n",
    "<li>sibsp - Количество братьев/сестер или супругов на борту</li>\n",
    "<li>parch - Количество родителей/детей на борту</li>\n",
    "<li>fare - Стоимость билета пассажира</li>\n",
    "<li>embarked - Порт посадки (C = Шербур; Q = Квинстаун; S = Саутгемптон)</li>\n",
    "<li>Age_priority - приоритет для детей 0-10 лет </li>\n",
    "<li>Has_1_to_3_Parch - семья от 1 до 3 человек </li>\n",
    "<li>Is_First_Class - человек живет в первом классе</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5c8cd",
   "metadata": {},
   "source": [
    "1.1 Сравнение моделей разной глубины (15 баллов)\n",
    " <br>Создайте и обучите модели с различным количеством слоев:<br>\n",
    " - 1 слой (линейный классификатор)\n",
    " - 2 слоя (1 скрытый)\n",
    " - 3 слоя (2 скрытых)\n",
    " - 5 слоев (4 скрытых)\n",
    " - 7 слоев (6 скрытых)\n",
    " \n",
    " Для каждого варианта:\n",
    " - Сравните точность на train и test\n",
    " - Визуализируйте кривые обучения\n",
    " - Проанализируйте время обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d776374",
   "metadata": {},
   "source": [
    "Создадим отдельные модели через nn.Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d80c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layer_1 = nn.Sequential(nn.Linear(11,1))\n",
    "model_layer_2 = nn.Sequential(nn.Linear(11,8),nn.Linear(8,1))\n",
    "model_layer_3 = nn.Sequential(nn.Linear(11,8),nn.Linear(8,6),nn.Linear(6,1))\n",
    "model_layer_5 = nn.Sequential(nn.Linear(11,8),nn.Linear(8,6),nn.Linear(6,4),nn.Linear(4,2),nn.Linear(2,1))\n",
    "model_layer_7 = nn.Sequential(nn.Linear(11,8),nn.Linear(8,6),nn.Linear(6,4),nn.Linear(4,4),nn.Linear(4,4),nn.Linear(4,2),nn.Linear(2,1))\n",
    "\n",
    "all_model =[model_layer_1,model_layer_2,model_layer_3,model_layer_5,model_layer_7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eead2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b6d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from lesson_2 import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cc365e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "\n",
    "\n",
    "def train_model(dataset,model):\n",
    "    batch_size: int = 32,\n",
    "    num_epochs: int = 100,\n",
    "    learning_rate = 0.001,\n",
    "    l1_lambda: float = 0.01,\n",
    "    patience: int = 5,\n",
    "    validation_split: float = 0.2\n",
    "    lr = 0.001\n",
    "\n",
    "    in_features = len(dataset.df.columns) - 1  # Все колонки, кроме целевой\n",
    "    \n",
    "    out_features = 1 \n",
    "\n",
    "    #model_layer_1 = nn.Sequential(nn.Linear(in_features,1))\n",
    "    model = model\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Функция потерь для регрессии\n",
    "    optimizer = torch.optim.Adam(params =model.parameters(), lr=lr)\n",
    "\n",
    "    # Разделяем данные на обучающую и валидационную выборки\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        indices, test_size=validation_split, random_state=42\n",
    "    )\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n",
    "\n",
    "    # Инициализируем раннюю остановку\n",
    "\n",
    "\n",
    "    # Обучение\n",
    "    print(\"Starting training...\")\n",
    "    arr_val_loss = []\n",
    "    arr_train_loss = []\n",
    "    for epoch in range(60):\n",
    "        # Обучающий режим\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to( dtype=torch.float32), target.to(dtype=torch.float32)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to( dtype=torch.float32), target.to( dtype=torch.float32)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target.view(-1, 1))  # Только MSE для валидации\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        arr_val_loss.append(avg_val_loss)\n",
    "        arr_train_loss.append(avg_train_loss)\n",
    "        if epoch%20==0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "    plt.plot(arr_val_loss)\n",
    "    plt.plot(arr_train_loss)\n",
    "    plt.title(f\"model_layer_{len(model)}\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(['Val', 'Train'], loc='upper left')  \n",
    "    plt.savefig(f'plots/plots_without_accurasy/model_layer_{len(model)}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031bb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2129af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now train model_layer_1\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.445789, Val Loss: 0.517851\n",
      "Epoch 21/(100,), Train Loss: 0.447471, Val Loss: 0.456000\n",
      "Epoch 41/(100,), Train Loss: 0.446935, Val Loss: 0.463320\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_2\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.445267, Val Loss: 0.553689\n",
      "Epoch 21/(100,), Train Loss: 0.487153, Val Loss: 0.469601\n",
      "Epoch 41/(100,), Train Loss: 0.461984, Val Loss: 0.464636\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_3\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.467646, Val Loss: 0.447486\n",
      "Epoch 21/(100,), Train Loss: 0.461505, Val Loss: 0.463796\n",
      "Epoch 41/(100,), Train Loss: 0.461859, Val Loss: 0.484375\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_5\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.457384, Val Loss: 0.489109\n",
      "Epoch 21/(100,), Train Loss: 0.432891, Val Loss: 0.490020\n",
      "Epoch 41/(100,), Train Loss: 0.445492, Val Loss: 0.479709\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_7\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.498698, Val Loss: 0.461519\n",
      "Epoch 21/(100,), Train Loss: 0.457258, Val Loss: 0.471696\n",
      "Epoch 41/(100,), Train Loss: 0.433530, Val Loss: 0.467168\n",
      "Succes!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(path_file=\"data/titanic_new.csv\",numeric_columns=[\"Age\",\"Fare\"],string_columns=[],binary_columns=[]\n",
    "                       \n",
    "                        ,target_column=\"Survived\")\n",
    "\n",
    "for model in all_model:\n",
    "    print(f\"Now train model_layer_{len(model)}\")\n",
    "    train_model(dataset,model)\n",
    "    print(\"Succes!\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fab933",
   "metadata": {},
   "source": [
    "Смотря на графики мы видим что разница между количеством слоёв в результате небольшая,также видим не стабильное изменение loss  в разных эпохах,хотя ,например,разница по времени обучения между 1 слоём и 7 существенна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654bb20",
   "metadata": {},
   "source": [
    "# 1.2 Анализ переобучения (15 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bde5e6",
   "metadata": {},
   "source": [
    " Исследуйте влияние глубины на переобучение:\n",
    " - Постройте графики train/test accuracy по эпохам\n",
    " - Определите оптимальную глубину для каждого датасета\n",
    " - Добавьте Dropout и BatchNorm, сравните результаты\n",
    " - Проанализируйте, когда начинается переобучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d56d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "\n",
    "\n",
    "def train_model_with_accurasy(dataset,model):\n",
    "    batch_size: int = 32,\n",
    "    num_epochs: int = 100,\n",
    "    learning_rate = 0.001,\n",
    "    l1_lambda: float = 0.01,\n",
    "    patience: int = 5,\n",
    "    validation_split: float = 0.2\n",
    "    lr = 0.001\n",
    "\n",
    "    in_features = len(dataset.df.columns) - 1  # Все колонки, кроме целевой\n",
    "    \n",
    "    out_features = 1 \n",
    "\n",
    "    #model_layer_1 = nn.Sequential(nn.Linear(in_features,1))\n",
    "    model = model\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Функция потерь для регрессии\n",
    "    optimizer = torch.optim.Adam(params =model.parameters(), lr=lr)\n",
    "\n",
    "    # Разделяем данные на обучающую и валидационную выборки\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        indices, test_size=validation_split, random_state=42\n",
    "    )\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n",
    "\n",
    "    # Инициализируем раннюю остановку\n",
    "\n",
    "\n",
    "    # Обучение\n",
    "    print(\"Starting training...\")\n",
    "    arr_val_accurasy = []\n",
    "    arr_train_accurasy = []\n",
    "    for epoch in range(60):\n",
    "        # Обучающий режим\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to( dtype=torch.float32), target.to(dtype=torch.float32)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Вычисляем точность для тренировочной выборки\n",
    "            preds = (torch.sigmoid(output) > 0.5).float()  # Преобразуем логиты в предсказания (0 или 1)\n",
    "            train_correct += (preds == target.view(-1, 1)).sum().item()\n",
    "            train_total += target.size(0)\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to( dtype=torch.float32), target.to( dtype=torch.float32)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target.view(-1, 1))  # Только MSE для валидации\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Вычисляем точность для валидационной выборки\n",
    "                preds = (torch.sigmoid(output) > 0.5).float()  # Преобразуем логиты в предсказания\n",
    "                val_correct += (preds == target.view(-1, 1)).sum().item()\n",
    "                val_total += target.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        arr_val_accurasy.append(val_accuracy)\n",
    "        arr_train_accurasy.append(train_accuracy)\n",
    "        \n",
    "        if epoch%20==0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "    plt.plot(arr_val_accurasy)\n",
    "    plt.plot(arr_train_accurasy)\n",
    "    plt.title(f\"model_layer_5\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(['Val', 'Train'], loc='upper left')  \n",
    "    plt.savefig(f'plots/plots_with_accurasy_dropout/model_layer_5.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787fb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now train model_layer_1\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.435743, Val Loss: 0.475915\n",
      "Epoch 21/(100,), Train Loss: 0.438628, Val Loss: 0.454661\n",
      "Epoch 41/(100,), Train Loss: 0.442064, Val Loss: 0.500347\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_2\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.465860, Val Loss: 0.507726\n",
      "Epoch 21/(100,), Train Loss: 0.434508, Val Loss: 0.448856\n",
      "Epoch 41/(100,), Train Loss: 0.453488, Val Loss: 0.472664\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_3\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.470745, Val Loss: 0.485388\n",
      "Epoch 21/(100,), Train Loss: 0.441853, Val Loss: 0.478778\n",
      "Epoch 41/(100,), Train Loss: 0.436443, Val Loss: 0.479067\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_5\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.463183, Val Loss: 0.445459\n",
      "Epoch 21/(100,), Train Loss: 0.454532, Val Loss: 0.525905\n",
      "Epoch 41/(100,), Train Loss: 0.456850, Val Loss: 0.523833\n",
      "Succes!\n",
      "\n",
      "Now train model_layer_7\n",
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.501815, Val Loss: 0.545296\n",
      "Epoch 21/(100,), Train Loss: 0.462030, Val Loss: 0.463708\n",
      "Epoch 41/(100,), Train Loss: 0.435991, Val Loss: 0.470550\n",
      "Succes!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(path_file=\"data/titanic_new.csv\",numeric_columns=[\"Age\",\"Fare\"],string_columns=[],binary_columns=[]\n",
    "                       \n",
    "                        ,target_column=\"Survived\")\n",
    "\n",
    "for model in all_model:\n",
    "    print(f\"Now train model_layer_{len(model)}\")\n",
    "    train_model_with_accurasy(dataset,model)\n",
    "    print(\"Succes!\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9615f9",
   "metadata": {},
   "source": [
    "В целом разница по слоям незначительна,но всё же результаты в среднем лучше на пяти слоях"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a7060",
   "metadata": {},
   "source": [
    "Сейчас добавлю в эту модель Dropout и Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a8aca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layer_5_ = nn.Sequential(nn.Linear(11,8),nn.Dropout(0.2),nn.BatchNorm1d(8),\n",
    "                              nn.Linear(8,6),nn.Dropout(0.2),nn.BatchNorm1d(6),\n",
    "                              nn.Linear(6,4),nn.Dropout(0.2),nn.BatchNorm1d(4),\n",
    "                              nn.Linear(4,2),nn.Dropout(0.2),nn.BatchNorm1d(2),\n",
    "                              nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "735c6ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/(100,), Train Loss: 0.441318, Val Loss: 0.473886\n",
      "Epoch 21/(100,), Train Loss: 0.456014, Val Loss: 0.516599\n",
      "Epoch 41/(100,), Train Loss: 0.475269, Val Loss: 0.514133\n"
     ]
    }
   ],
   "source": [
    "train_model_with_accurasy(dataset,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4576f",
   "metadata": {},
   "source": [
    "График стал более гладким,переобучение пошло примерно с тридцатой эпохи"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
