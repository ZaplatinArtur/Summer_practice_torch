{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1103e06",
   "metadata": {},
   "source": [
    "# Задание 2: Эксперименты с шириной сети (25 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b9ebda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationMetrics:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Инициализация класса метрик классификации\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def to_one_hot(self, labels, num_classes):\n",
    "        \"\"\"\n",
    "        Преобразование меток в one-hot encoding\n",
    "        \n",
    "        Args:\n",
    "            labels: тензор меток (batch_size,)\n",
    "            num_classes: количество классов\n",
    "            \n",
    "        Returns:\n",
    "            one-hot тензор (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        return torch.nn.functional.one_hot(labels, num_classes).float()\n",
    "\n",
    "    def precision(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики Precision\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            precision score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        \n",
    "        if average == 'micro':\n",
    "            true_positives = torch.sum(y_true == y_pred).float()\n",
    "            predicted_positives = len(y_pred)\n",
    "            return true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "        \n",
    "        precision_per_class = []\n",
    "        weights = []\n",
    "        \n",
    "        for c in range(num_classes):\n",
    "            true_positives = torch.sum((y_true == c) & (y_pred == c)).float()\n",
    "            predicted_positives = torch.sum(y_pred == c).float()\n",
    "            \n",
    "            precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "            precision_per_class.append(precision)\n",
    "            \n",
    "            if average == 'weighted':\n",
    "                weights.append(torch.sum(y_true == c).float() / len(y_true))\n",
    "        \n",
    "        precision_per_class = torch.tensor(precision_per_class)\n",
    "        \n",
    "        if average == 'macro':\n",
    "            return torch.mean(precision_per_class).item()\n",
    "        elif average == 'weighted':\n",
    "            return torch.sum(precision_per_class * torch.tensor(weights)).item()\n",
    "        \n",
    "        return precision_per_class.tolist()\n",
    "\n",
    "    def recall(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики Recall\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            recall score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        \n",
    "        if average == 'micro':\n",
    "            true_positives = torch.sum(y_true == y_pred).float()\n",
    "            actual_positives = len(y_true)\n",
    "            return true_positives / actual_positives if actual_positives > 0 else 0\n",
    "        \n",
    "        recall_per_class = []\n",
    "        weights = []\n",
    "        \n",
    "        for c in range(num_classes):\n",
    "            true_positives = torch.sum((y_true == c) & (y_pred == c)).float()\n",
    "            actual_positives = torch.sum(y_true == c).float()\n",
    "            \n",
    "            recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "            recall_per_class.append(recall)\n",
    "            \n",
    "            if average == 'weighted':\n",
    "                weights.append(torch.sum(y_true == c).float() / len(y_true))\n",
    "        \n",
    "        recall_per_class = torch.tensor(recall_per_class)\n",
    "        \n",
    "        if average == 'macro':\n",
    "            return torch.mean(recall_per_class).item()\n",
    "        elif average == 'weighted':\n",
    "            return torch.sum(recall_per_class * torch.tensor(weights)).item()\n",
    "        \n",
    "        return recall_per_class.tolist()\n",
    "\n",
    "    def f1_score(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики F1-score\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            f1 score\n",
    "        \"\"\"\n",
    "        precision = self.precision(y_true, y_pred, average)\n",
    "        recall = self.recall(y_true, y_pred, average)\n",
    "        \n",
    "        if average in ['macro', 'weighted']:\n",
    "            return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        elif average == 'micro':\n",
    "            return precision\n",
    "        \n",
    "        f1_scores = []\n",
    "        for p, r in zip(precision, recall):\n",
    "            f1 = 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "            f1_scores.append(f1)\n",
    "        return f1_scores\n",
    "\n",
    "    def roc_auc(self, y_true, y_scores, multi_class='ovr'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики ROC-AUC\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_scores: вероятности предсказаний (batch_size, num_classes)\n",
    "            multi_class: 'ovr' (one-vs-rest) или 'ovo' (one-vs-one)\n",
    "            \n",
    "        Returns:\n",
    "            roc-auc score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).cpu().numpy()\n",
    "        y_scores = torch.tensor(y_scores, dtype=torch.float).cpu().numpy()\n",
    "        \n",
    "        num_classes = y_scores.shape[1]\n",
    "        y_true_one_hot = self.to_one_hot(torch.tensor(y_true), num_classes).cpu().numpy()\n",
    "        \n",
    "        auc_scores = []\n",
    "        \n",
    "        if multi_class == 'ovr':\n",
    "            for i in range(num_classes):\n",
    "                fpr, tpr, _ = roc_curve(y_true_one_hot[:, i], y_scores[:, i])\n",
    "                auc_score = auc(fpr, tpr)\n",
    "                auc_scores.append(auc_score)\n",
    "            return np.mean(auc_scores)\n",
    "        \n",
    "        elif multi_class == 'ovo':\n",
    "            auc_sum = 0\n",
    "            n_pairs = 0\n",
    "            for i in range(num_classes):\n",
    "                for j in range(i+1, num_classes):\n",
    "                    mask = np.logical_or(y_true == i, y_true == j)\n",
    "                    y_true_binary = (y_true[mask] == i).astype(int)\n",
    "                    y_scores_binary = y_scores[mask, i] / (y_scores[mask, i] + y_scores[mask, j])\n",
    "                    fpr, tpr, _ = roc_curve(y_true_binary, y_scores_binary)\n",
    "                    auc_sum += auc(fpr, tpr)\n",
    "                    n_pairs += 1\n",
    "            return auc_sum / n_pairs if n_pairs > 0 else 0\n",
    "        \n",
    "        return auc_scores\n",
    "\n",
    "    def confusion_matrix(self, y_true, y_pred, plot=True, save_path=None):\n",
    "        \"\"\"\n",
    "        Вычисление и визуализация confusion matrix с возможностью сохранения\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            plot: флаг для отображения визуализации\n",
    "            save_path: путь для сохранения графика (например, 'confusion_matrix.png')\n",
    "            \n",
    "        Returns:\n",
    "            confusion matrix\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        cm = torch.zeros((num_classes, num_classes), dtype=torch.long)\n",
    "        \n",
    "        for t, p in zip(y_true, y_pred):\n",
    "            cm[t, p] += 1\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm.numpy(), annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            \n",
    "            if save_path:\n",
    "                # Создаём директорию, если она не существует\n",
    "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "                print(f\"Confusion matrix сохранена в {save_path}\")\n",
    "            \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "        return cm\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path_file, numeric_columns: list, string_columns: list, binary_columns: list, target_column: str):\n",
    "        self.path_file = path_file\n",
    "        self.numeric_columns = numeric_columns\n",
    "        self.string_columns = string_columns\n",
    "        self.binary_columns = binary_columns\n",
    "        self.target_column = target_column\n",
    "        self.label_encoders = {}\n",
    "        self.one_hot_encoders = {}\n",
    "\n",
    "        self.df = pd.read_csv(path_file)\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "        self._convert_numeric()\n",
    "        self._convert_string()\n",
    "        self._convert_binary()\n",
    "\n",
    "    def _convert_numeric(self):\n",
    "        if self.numeric_columns:\n",
    "            scaler = StandardScaler()\n",
    "            self.df[self.numeric_columns] = scaler.fit_transform(self.df[self.numeric_columns])\n",
    "\n",
    "    def _convert_string(self):\n",
    "        if self.string_columns:\n",
    "            for column in self.string_columns:\n",
    "                le = LabelEncoder()\n",
    "                self.df[column] = self.df[column].fillna('missing')\n",
    "                self.df[column] = le.fit_transform(self.df[column])\n",
    "                self.label_encoders[column] = le\n",
    "\n",
    "    def _convert_binary(self):\n",
    "        if self.binary_columns:\n",
    "            for column in self.binary_columns:\n",
    "                encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "                transformed = encoder.fit_transform(self.df[[column]])\n",
    "                new_columns = [f\"{column}_{cat}\" for cat in encoder.categories_[0][1:]]\n",
    "                self.df[new_columns] = transformed\n",
    "                self.df = self.df.drop(column, axis=1)\n",
    "                self.one_hot_encoders[column] = encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_one_row = self.df.iloc[index]\n",
    "        train = data_one_row.drop(self.target_column).values.astype(np.float32)  # Преобразуем в numpy float32\n",
    "        target = np.array(data_one_row[self.target_column], dtype=np.float32)  # Преобразуем в numpy float32\n",
    "        return torch.tensor(train), torch.tensor(target)  # Возвращаем тензоры\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self,in_features,out_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features,out_features)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layer1(x)\n",
    "\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "\n",
    "\n",
    "def train_model(dataset,model):\n",
    "    batch_size: int = 32,\n",
    "    num_epochs: int = 100,\n",
    "    learning_rate = 0.001,\n",
    "    l1_lambda: float = 0.01,\n",
    "    patience: int = 5,\n",
    "    validation_split: float = 0.2\n",
    "    lr = 0.001\n",
    "\n",
    "    in_features = len(dataset.df.columns) - 1  # Все колонки, кроме целевой\n",
    "    \n",
    "    out_features = 1 \n",
    "\n",
    "    #model_layer_1 = nn.Sequential(nn.Linear(in_features,1))\n",
    "    model = model\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Функция потерь для регрессии\n",
    "    optimizer = torch.optim.Adam(params =model.parameters(), lr=lr)\n",
    "\n",
    "    # Разделяем данные на обучающую и валидационную выборки\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        indices, test_size=validation_split, random_state=42\n",
    "    )\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n",
    "\n",
    "    # Инициализируем раннюю остановку\n",
    "\n",
    "\n",
    "    # Обучение\n",
    "    print(\"Starting training...\")\n",
    "    arr_val_loss = []\n",
    "    arr_train_loss = []\n",
    "    for epoch in range(60):\n",
    "        # Обучающий режим\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to( dtype=torch.float32), target.to(dtype=torch.float32)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to( dtype=torch.float32), target.to( dtype=torch.float32)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target.view(-1, 1))  # Только MSE для валидации\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        arr_val_loss.append(avg_val_loss)\n",
    "        arr_train_loss.append(avg_train_loss)\n",
    "        if epoch%20==0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "    plt.plot(arr_val_loss)\n",
    "    plt.plot(arr_train_loss)\n",
    "    plt.title(f\"model_layer_{len(model)}\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(['Val', 'Train'], loc='upper left')  \n",
    "    plt.savefig(f'plots/plots_wide_layers/model_layer_{len(model)}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "\n",
    "\n",
    "def train_model_with_accurasy(dataset,model,name_model):\n",
    "    batch_size: int = 32,\n",
    "    num_epochs: int = 50,\n",
    "    learning_rate = 0.001,\n",
    "    l1_lambda: float = 0.01,\n",
    "    patience: int = 5,\n",
    "    validation_split: float = 0.2\n",
    "    lr = 0.001\n",
    "\n",
    "    in_features = len(dataset.df.columns) - 1  # Все колонки, кроме целевой\n",
    "    \n",
    "    out_features = 1 \n",
    "\n",
    "    #model_layer_1 = nn.Sequential(nn.Linear(in_features,1))\n",
    "    model = model\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Функция потерь для регрессии\n",
    "    optimizer = torch.optim.Adam(params =model.parameters(), lr=lr)\n",
    "\n",
    "    # Разделяем данные на обучающую и валидационную выборки\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        indices, test_size=validation_split, random_state=42\n",
    "    )\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n",
    "\n",
    "    # Инициализируем раннюю остановку\n",
    "\n",
    "\n",
    "    # Обучение\n",
    "    print(\"Starting training...\")\n",
    "    arr_val_accurasy = []\n",
    "    arr_train_accurasy = []\n",
    "    for epoch in range(50):\n",
    "        # Обучающий режим\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to( dtype=torch.float32), target.to(dtype=torch.float32)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Вычисляем точность для тренировочной выборки\n",
    "            preds = (torch.sigmoid(output) > 0.5).float()  # Преобразуем логиты в предсказания (0 или 1)\n",
    "            train_correct += (preds == target.view(-1, 1)).sum().item()\n",
    "            train_total += target.size(0)\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to( dtype=torch.float32), target.to( dtype=torch.float32)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target.view(-1, 1))  # Только MSE для валидации\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Вычисляем точность для валидационной выборки\n",
    "                preds = (torch.sigmoid(output) > 0.5).float()  # Преобразуем логиты в предсказания\n",
    "                val_correct += (preds == target.view(-1, 1)).sum().item()\n",
    "                val_total += target.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        arr_val_accurasy.append(val_accuracy)\n",
    "        arr_train_accurasy.append(train_accuracy)\n",
    "        \n",
    "        if epoch%20==0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "    plt.plot(arr_val_accurasy)\n",
    "    plt.plot(arr_train_accurasy)\n",
    "    plt.title(f\"model_layer_{model_name}\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(['Val', 'Train'], loc='upper left')  \n",
    "    plt.savefig(f'plots/plots_with_grid_search/{model_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba09100",
   "metadata": {},
   "source": [
    "2.1 Сравнение моделей разной ширины (15 баллов)\n",
    "<br> Создайте модели с различной шириной слоев:<br>\n",
    " - Узкие слои: [64, 32, 16]\n",
    " - Средние слои: [256, 128, 64]\n",
    " - Широкие слои: [1024, 512, 256]\n",
    " - Очень широкие слои: [2048, 1024, 512]\n",
    " \n",
    " Для каждого варианта:\n",
    " - Поддерживайте одинаковую глубину (3 слоя)\n",
    " - Сравните точность и время обучения\n",
    " - Проанализируйте количество параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f48aa8",
   "metadata": {},
   "source": [
    "Для каждой модели добавлю входной слой в 11 признаков,столько же сколько в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9420356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "narrow_layers = nn.Sequential(nn.Linear(11,64),nn.BatchNorm1d(64),\n",
    "                               nn.Linear(64,32),nn.BatchNorm1d(32),\n",
    "                               nn.Linear(32,16),nn.BatchNorm1d(16),\n",
    "                               nn.Linear(16,1) )\n",
    "\n",
    "middle_layers = nn.Sequential(nn.Linear(11,256),nn.BatchNorm1d(256),\n",
    "                               nn.Linear(256,128),nn.BatchNorm1d(128),\n",
    "                               nn.Linear(128,64),nn.BatchNorm1d(64),\n",
    "                               nn.Linear(64,1) )\n",
    "wide_layers = nn.Sequential(nn.Linear(11,1024),nn.BatchNorm1d(1024),\n",
    "                               nn.Linear(1024,256),nn.BatchNorm1d(256),\n",
    "                               nn.Linear(256,128),nn.BatchNorm1d(128),\n",
    "                               nn.Linear(128,1) )\n",
    "\n",
    "very_wide_layers = nn.Sequential(nn.Linear(11,2048),nn.BatchNorm1d(2048),\n",
    "                               nn.Linear(2048,1024),nn.BatchNorm1d(1024),\n",
    "                               nn.Linear(1024,512),nn.BatchNorm1d(512),\n",
    "                               nn.Linear(512,1) )\n",
    "\n",
    "\n",
    "all_wide_layers = {\n",
    "    \"narrow_layers\":narrow_layers,\n",
    "    \"middle_layers\":middle_layers,\n",
    "    \"wide_layers\":wide_layers,\n",
    "    \"very_wide_layers\":very_wide_layers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e9398c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train model narrow_layers\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.451675, Val Loss: 0.631376\n",
      "Epoch 21/(50,), Train Loss: 0.445325, Val Loss: 0.444352\n",
      "Epoch 41/(50,), Train Loss: 0.453868, Val Loss: 0.463770\n",
      "Succes! time train: 22.13288164138794\n",
      "Start train model middle_layers\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.635704, Val Loss: 0.630039\n",
      "Epoch 21/(50,), Train Loss: 0.444176, Val Loss: 0.710750\n",
      "Epoch 41/(50,), Train Loss: 0.440624, Val Loss: 0.462534\n",
      "Succes! time train: 26.327837467193604\n",
      "Start train model wide_layers\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.608002, Val Loss: 0.592849\n",
      "Epoch 21/(50,), Train Loss: 0.477022, Val Loss: 0.597559\n",
      "Epoch 41/(50,), Train Loss: 0.451993, Val Loss: 0.493352\n",
      "Succes! time train: 35.44964814186096\n",
      "Start train model very_wide_layers\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.616060, Val Loss: 0.577410\n",
      "Epoch 21/(50,), Train Loss: 0.472476, Val Loss: 0.592207\n",
      "Epoch 41/(50,), Train Loss: 0.457161, Val Loss: 0.586177\n",
      "Succes! time train: 52.57612895965576\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dataset = CustomDataset(path_file=\"data/titanic_new.csv\",numeric_columns=[\"Age\",\"Fare\"],string_columns=[],binary_columns=[]\n",
    "                       \n",
    "                        ,target_column=\"Survived\")\n",
    "with open(\"logi_time_wide_layers.txt\",\"w\") as f:\n",
    "    for model_name in all_wide_layers:\n",
    "        start_time = time.time()\n",
    "        print(f\"Start train model {model_name}\")\n",
    "        train_model_with_accurasy(dataset,all_wide_layers[model_name],model_name)\n",
    "        end_time = time.time()\n",
    "        print(f\"Succes! time train: {end_time-start_time}\")\n",
    "        f.write(f\"time train model {model_name} is {end_time-start_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56417776",
   "metadata": {},
   "source": [
    "точность выше всего у модели с наименьшим числом параметров,также и меньше её время обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d49938e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.693218, Val Loss: 0.668224\n",
      "Epoch 21/(50,), Train Loss: 0.446379, Val Loss: 0.650202\n",
      "Epoch 41/(50,), Train Loss: 0.451587, Val Loss: 0.447531\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.663028, Val Loss: 0.667308\n",
      "Epoch 21/(50,), Train Loss: 0.461313, Val Loss: 1.136339\n",
      "Epoch 41/(50,), Train Loss: 0.457360, Val Loss: 0.490809\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.692599, Val Loss: 0.683698\n",
      "Epoch 21/(50,), Train Loss: 0.451567, Val Loss: 0.500134\n",
      "Epoch 41/(50,), Train Loss: 0.439133, Val Loss: 0.471544\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.654409, Val Loss: 0.648752\n",
      "Epoch 21/(50,), Train Loss: 0.472848, Val Loss: 0.638136\n",
      "Epoch 41/(50,), Train Loss: 0.446457, Val Loss: 0.657468\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.621337, Val Loss: 0.828584\n",
      "Epoch 21/(50,), Train Loss: 0.478652, Val Loss: 0.651763\n",
      "Epoch 41/(50,), Train Loss: 0.458630, Val Loss: 0.584196\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.627397, Val Loss: 0.692931\n",
      "Epoch 21/(50,), Train Loss: 0.454439, Val Loss: 0.752051\n",
      "Epoch 41/(50,), Train Loss: 0.467124, Val Loss: 0.476530\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.643269, Val Loss: 0.652711\n",
      "Epoch 21/(50,), Train Loss: 0.463912, Val Loss: 1.425037\n",
      "Epoch 41/(50,), Train Loss: 0.471743, Val Loss: 0.471128\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.692347, Val Loss: 0.716829\n",
      "Epoch 21/(50,), Train Loss: 0.487979, Val Loss: 0.510831\n",
      "Epoch 41/(50,), Train Loss: 0.428865, Val Loss: 0.523159\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.601719, Val Loss: 0.643873\n",
      "Epoch 21/(50,), Train Loss: 0.466714, Val Loss: 0.978675\n",
      "Epoch 41/(50,), Train Loss: 0.459071, Val Loss: 0.462530\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.641045, Val Loss: 0.697585\n",
      "Epoch 21/(50,), Train Loss: 0.448222, Val Loss: 0.559077\n",
      "Epoch 41/(50,), Train Loss: 0.460992, Val Loss: 0.482372\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.649615, Val Loss: 0.653302\n",
      "Epoch 21/(50,), Train Loss: 0.466731, Val Loss: 0.728245\n",
      "Epoch 41/(50,), Train Loss: 0.454279, Val Loss: 0.471478\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.652862, Val Loss: 0.688229\n",
      "Epoch 21/(50,), Train Loss: 0.473843, Val Loss: 0.491360\n",
      "Epoch 41/(50,), Train Loss: 0.458600, Val Loss: 0.497399\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.632550, Val Loss: 0.646011\n",
      "Epoch 21/(50,), Train Loss: 0.484966, Val Loss: 0.501259\n",
      "Epoch 41/(50,), Train Loss: 0.440794, Val Loss: 0.493733\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.615465, Val Loss: 0.619445\n",
      "Epoch 21/(50,), Train Loss: 0.445579, Val Loss: 0.491680\n",
      "Epoch 41/(50,), Train Loss: 0.462067, Val Loss: 0.535391\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.707266, Val Loss: 0.684946\n",
      "Epoch 21/(50,), Train Loss: 0.456278, Val Loss: 0.523785\n",
      "Epoch 41/(50,), Train Loss: 0.463074, Val Loss: 0.471714\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.673223, Val Loss: 0.688340\n",
      "Epoch 21/(50,), Train Loss: 0.439230, Val Loss: 0.710197\n",
      "Epoch 41/(50,), Train Loss: 0.464690, Val Loss: 0.552893\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.661682, Val Loss: 0.701765\n",
      "Epoch 21/(50,), Train Loss: 0.455840, Val Loss: 2.470547\n",
      "Epoch 41/(50,), Train Loss: 0.449155, Val Loss: 0.480509\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.674522, Val Loss: 0.663083\n",
      "Epoch 21/(50,), Train Loss: 0.462489, Val Loss: 0.640271\n",
      "Epoch 41/(50,), Train Loss: 0.448599, Val Loss: 0.562835\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.650272, Val Loss: 0.643103\n",
      "Epoch 21/(50,), Train Loss: 0.468078, Val Loss: 0.476233\n",
      "Epoch 41/(50,), Train Loss: 0.448637, Val Loss: 0.463214\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.621866, Val Loss: 0.634477\n",
      "Epoch 21/(50,), Train Loss: 0.469279, Val Loss: 0.493017\n",
      "Epoch 41/(50,), Train Loss: 0.453796, Val Loss: 0.555088\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.697682, Val Loss: 0.773719\n",
      "Epoch 21/(50,), Train Loss: 0.460558, Val Loss: 0.539431\n",
      "Epoch 41/(50,), Train Loss: 0.462227, Val Loss: 0.478378\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.681134, Val Loss: 0.743129\n",
      "Epoch 21/(50,), Train Loss: 0.467542, Val Loss: 0.800497\n",
      "Epoch 41/(50,), Train Loss: 0.466734, Val Loss: 0.540166\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.630436, Val Loss: 0.720794\n",
      "Epoch 21/(50,), Train Loss: 0.457229, Val Loss: 0.495048\n",
      "Epoch 41/(50,), Train Loss: 0.439807, Val Loss: 0.487352\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.610192, Val Loss: 0.638302\n",
      "Epoch 21/(50,), Train Loss: 0.470968, Val Loss: 0.673850\n",
      "Epoch 41/(50,), Train Loss: 0.462234, Val Loss: 0.601676\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.629650, Val Loss: 0.643069\n",
      "Epoch 21/(50,), Train Loss: 0.494280, Val Loss: 0.559117\n",
      "Epoch 41/(50,), Train Loss: 0.439092, Val Loss: 0.459729\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.619208, Val Loss: 0.655973\n",
      "Epoch 21/(50,), Train Loss: 0.447682, Val Loss: 0.489951\n",
      "Epoch 41/(50,), Train Loss: 0.429712, Val Loss: 0.517824\n",
      "Starting training...\n",
      "Epoch 1/(50,), Train Loss: 0.575202, Val Loss: 0.721441\n",
      "Epoch 21/(50,), Train Loss: 0.458635, Val Loss: 0.478145\n",
      "Epoch 41/(50,), Train Loss: 0.454226, Val Loss: 0.694393\n"
     ]
    }
   ],
   "source": [
    "wide_layers = [16,32,64]\n",
    "\n",
    "for i in wide_layers:\n",
    "    for j in wide_layers:\n",
    "        for k in wide_layers:\n",
    "            model_name = f\"model_{i}_{j}_{k}\"\n",
    "            model = nn.Sequential(nn.Linear(11,i),nn.BatchNorm1d(i),\n",
    "                                nn.Linear(i,j),nn.BatchNorm1d(j),\n",
    "                                nn.Linear(j,k),nn.BatchNorm1d(k),\n",
    "                                nn.Linear(k,1))\n",
    "            train_model_with_accurasy(dataset,model,model_name)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6666ea2",
   "metadata": {},
   "source": [
    "лучше всего себя показали расширяющие модели ,причем с небольшим числом параметров 16-32-16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
