{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d1cb4e",
   "metadata": {},
   "source": [
    "# Задание 1: Модификация существующих моделей (30 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fa45b",
   "metadata": {},
   "source": [
    "1.1 Расширение линейной регрессии (15 баллов)\n",
    " <br>Модифицируйте существующую линейную регрессию:<br>\n",
    " - Добавьте L1 и L2 регуляризацию\n",
    " - Добавьте early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self,in_features,out_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features,out_features)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layer1(x)\n",
    "\n",
    "\n",
    "#l1_loss \n",
    "def l1_loss(output, target, activations, criterion, l1_lambda):\n",
    "    main_loss = criterion(output, target)\n",
    "    l1_penalty = torch.norm(activations, p=1)\n",
    "    return main_loss + l1_lambda * l1_penalty\n",
    "\n",
    "\n",
    "#класс для ранней остановки\n",
    "class EarlyStopping:\n",
    "    \"\"\"\"\n",
    "    patience-количество эпох, которые нужно подождать, прежде чем остановиться, если улучшения не будет.\n",
    "    delta-Minimum change in the monitored quantity to qualify as an improvement.\n",
    "    best_score,best_model_state -Track the best validation score and model state.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f1ca8",
   "metadata": {},
   "source": [
    "Пример обучения со всеми добавлениями(L2-loss добавлю использую здесь т.к оно уже реализовано в оптимизаторах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e06db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = LinearModel(10,1)\n",
    "\n",
    "train_loader = ... #какая-то тренировачная выборка\n",
    "val_loader = ... #какая-то валидационная выборка\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=0.01)#weight_decay и отвечает за L2-регуляризацию\n",
    "early_stopping = EarlyStopping(patience=5, delta=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "early_stopping.load_best_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278b8bb",
   "metadata": {},
   "source": [
    "<br>1.2 Расширение логистической регрессии (15 баллов)<br>\n",
    "Модифицируйте существующую логистическую регрессию:\n",
    " - Добавьте поддержку многоклассовой классификации\n",
    " - Реализуйте метрики: precision, recall, F1-score, ROC-AUC\n",
    " - Добавьте визуализацию confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96e07f",
   "metadata": {},
   "source": [
    "Добавим поддержку многокласовой классификации с помощью количества нейронов на последнем слое равным количеству классов и с помощью функции потерь torch.nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "class ClassificationMetrics:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Инициализация класса метрик классификации\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def to_one_hot(self, labels, num_classes):\n",
    "        \"\"\"\n",
    "        Преобразование меток в one-hot encoding\n",
    "        \n",
    "        Args:\n",
    "            labels: тензор меток (batch_size,)\n",
    "            num_classes: количество классов\n",
    "            \n",
    "        Returns:\n",
    "            one-hot тензор (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        return torch.nn.functional.one_hot(labels, num_classes).float()\n",
    "\n",
    "    def precision(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики Precision\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            precision score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        \n",
    "        if average == 'micro':\n",
    "            true_positives = torch.sum(y_true == y_pred).float()\n",
    "            predicted_positives = len(y_pred)\n",
    "            return true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "        \n",
    "        precision_per_class = []\n",
    "        weights = []\n",
    "        \n",
    "        for c in range(num_classes):\n",
    "            true_positives = torch.sum((y_true == c) & (y_pred == c)).float()\n",
    "            predicted_positives = torch.sum(y_pred == c).float()\n",
    "            \n",
    "            precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "            precision_per_class.append(precision)\n",
    "            \n",
    "            if average == 'weighted':\n",
    "                weights.append(torch.sum(y_true == c).float() / len(y_true))\n",
    "        \n",
    "        precision_per_class = torch.tensor(precision_per_class)\n",
    "        \n",
    "        if average == 'macro':\n",
    "            return torch.mean(precision_per_class).item()\n",
    "        elif average == 'weighted':\n",
    "            return torch.sum(precision_per_class * torch.tensor(weights)).item()\n",
    "        \n",
    "        return precision_per_class.tolist()\n",
    "\n",
    "    def recall(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики Recall\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            recall score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        \n",
    "        if average == 'micro':\n",
    "            true_positives = torch.sum(y_true == y_pred).float()\n",
    "            actual_positives = len(y_true)\n",
    "            return true_positives / actual_positives if actual_positives > 0 else 0\n",
    "        \n",
    "        recall_per_class = []\n",
    "        weights = []\n",
    "        \n",
    "        for c in range(num_classes):\n",
    "            true_positives = torch.sum((y_true == c) & (y_pred == c)).float()\n",
    "            actual_positives = torch.sum(y_true == c).float()\n",
    "            \n",
    "            recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "            recall_per_class.append(recall)\n",
    "            \n",
    "            if average == 'weighted':\n",
    "                weights.append(torch.sum(y_true == c).float() / len(y_true))\n",
    "        \n",
    "        recall_per_class = torch.tensor(recall_per_class)\n",
    "        \n",
    "        if average == 'macro':\n",
    "            return torch.mean(recall_per_class).item()\n",
    "        elif average == 'weighted':\n",
    "            return torch.sum(recall_per_class * torch.tensor(weights)).item()\n",
    "        \n",
    "        return recall_per_class.tolist()\n",
    "\n",
    "    def f1_score(self, y_true, y_pred, average='macro'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики F1-score\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            average: тип усреднения ('macro', 'micro', 'weighted')\n",
    "            \n",
    "        Returns:\n",
    "            f1 score\n",
    "        \"\"\"\n",
    "        precision = self.precision(y_true, y_pred, average)\n",
    "        recall = self.recall(y_true, y_pred, average)\n",
    "        \n",
    "        if average in ['macro', 'weighted']:\n",
    "            return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        elif average == 'micro':\n",
    "            return precision\n",
    "        \n",
    "        f1_scores = []\n",
    "        for p, r in zip(precision, recall):\n",
    "            f1 = 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "            f1_scores.append(f1)\n",
    "        return f1_scores\n",
    "\n",
    "    def roc_auc(self, y_true, y_scores, multi_class='ovr'):\n",
    "        \"\"\"\n",
    "        Вычисление метрики ROC-AUC\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_scores: вероятности предсказаний (batch_size, num_classes)\n",
    "            multi_class: 'ovr' (one-vs-rest) или 'ovo' (one-vs-one)\n",
    "            \n",
    "        Returns:\n",
    "            roc-auc score\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).cpu().numpy()\n",
    "        y_scores = torch.tensor(y_scores, dtype=torch.float).cpu().numpy()\n",
    "        \n",
    "        num_classes = y_scores.shape[1]\n",
    "        y_true_one_hot = self.to_one_hot(torch.tensor(y_true), num_classes).cpu().numpy()\n",
    "        \n",
    "        auc_scores = []\n",
    "        \n",
    "        if multi_class == 'ovr':\n",
    "            for i in range(num_classes):\n",
    "                fpr, tpr, _ = roc_curve(y_true_one_hot[:, i], y_scores[:, i])\n",
    "                auc_score = auc(fpr, tpr)\n",
    "                auc_scores.append(auc_score)\n",
    "            return np.mean(auc_scores)\n",
    "        \n",
    "        elif multi_class == 'ovo':\n",
    "            auc_sum = 0\n",
    "            n_pairs = 0\n",
    "            for i in range(num_classes):\n",
    "                for j in range(i+1, num_classes):\n",
    "                    mask = np.logical_or(y_true == i, y_true == j)\n",
    "                    y_true_binary = (y_true[mask] == i).astype(int)\n",
    "                    y_scores_binary = y_scores[mask, i] / (y_scores[mask, i] + y_scores[mask, j])\n",
    "                    fpr, tpr, _ = roc_curve(y_true_binary, y_scores_binary)\n",
    "                    auc_sum += auc(fpr, tpr)\n",
    "                    n_pairs += 1\n",
    "            return auc_sum / n_pairs if n_pairs > 0 else 0\n",
    "        \n",
    "        return auc_scores\n",
    "\n",
    "    def confusion_matrix(self, y_true, y_pred, plot=True, save_path=None):\n",
    "        \"\"\"\n",
    "        Вычисление и визуализация confusion matrix с возможностью сохранения\n",
    "        \n",
    "        Args:\n",
    "            y_true: истинные метки (batch_size,)\n",
    "            y_pred: предсказанные метки (batch_size,)\n",
    "            plot: флаг для отображения визуализации\n",
    "            save_path: путь для сохранения графика (например, 'confusion_matrix.png')\n",
    "            \n",
    "        Returns:\n",
    "            confusion matrix\n",
    "        \"\"\"\n",
    "        y_true = torch.tensor(y_true, dtype=torch.long).to(self.device)\n",
    "        y_pred = torch.tensor(y_pred, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        num_classes = len(torch.unique(y_true))\n",
    "        cm = torch.zeros((num_classes, num_classes), dtype=torch.long)\n",
    "        \n",
    "        for t, p in zip(y_true, y_pred):\n",
    "            cm[t, p] += 1\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm.numpy(), annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            \n",
    "            if save_path:\n",
    "                # Создаём директорию, если она не существует\n",
    "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "                print(f\"Confusion matrix сохранена в {save_path}\")\n",
    "            \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "        return cm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
